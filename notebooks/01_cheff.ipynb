{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Introduction: Cheff\n",
    "\n",
    "This notebook is a tutorial on how to load the Cheff Pipeline and synthesize Chest X-rays.\n",
    "Keep in mind that for an optimal user experience a GPU with at least 8GB VRAM is recommended."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms.functional import to_pil_image"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cheff LDM Module\n",
    "\n",
    "The Cheff LDM Module contains Phase 1 and 2 combined.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cheff import CheffLDM\n",
    "\n",
    "device = 'cuda'\n",
    "sdm_path = 'path/to/semantic_diffusion_model.pt'\n",
    "ae_path = 'path/to/autoencoder_model.pt'\n",
    "\n",
    "cheff_ldm = CheffLDM(model_path=sdm_path, ae_path=ae_path, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The path to the autoencoder is optional. In case of no supplied `ae_path`, the autoencoder will be initialized with random weights.\n",
    "\n",
    "A sample with a resolution of 256 pixels can be generated with the `sample` function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs = cheff_ldm.sample(\n",
    "    # Number of images to synthesize\n",
    "    batch_size=1,\n",
    "    # Number of DDIM sampling steps\n",
    "    sampling_steps=100,\n",
    "    # eta in DDIM sampling\n",
    "    eta=1.0,\n",
    "    # Use the AE decoder to translate from latent space.\n",
    "    decode=True\n",
    ")\n",
    "\n",
    "# The image are still in [-1, 1] so they need to be rescaled.\n",
    "imgs.clamp_(-1, 1)\n",
    "imgs = (imgs + 1) / 2\n",
    "\n",
    "# Show the produced images\n",
    "grid = make_grid(imgs.cpu())\n",
    "to_pil_image(grid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If `decode` is set to `False`, the function returns the latent embedding of the synthesized sample.\n",
    "\n",
    "## Cheff AE Module\n",
    "\n",
    "The autoencoder can also be loaded as a separate module, which is able to encode and decode images."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cheff import CheffAEModel\n",
    "\n",
    "device = 'cuda'\n",
    "ae_path = 'path/to/autoencoder_model.pt'\n",
    "\n",
    "cheff_ae = CheffAEModel(model_path=ae_path, device=device)\n",
    "\n",
    "# Create an \"image\"\n",
    "img = torch.rand((1, 3, 256, 256), device=device)\n",
    "\n",
    "# Encode image to latent space\n",
    "z = cheff_ae.encode(img)\n",
    "\n",
    "# Reconstruct images\n",
    "img_rec = cheff_ae.decode(z)\n",
    "\n",
    "# Check reconstruction quality\n",
    "grid = make_grid([img[0].cpu(), img_rec[0].cpu()])\n",
    "to_pil_image(grid)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cheff SR Module\n",
    "\n",
    "The super-resolution module follows a similar interface as the other two models.\n",
    "Note that this models works on a grayscale basis, whereas the rest of this stack still uses an RGB input.\n",
    "Running SR with the full DDPM denoising steps delivers the best results, but takes a lot of time and compute compared to DDIM sampling.\n",
    "When setting `ddim` as method the arguments `sampling_steps` and `eta` can be specified like in `CheffLDM`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cheff import CheffSRModel\n",
    "\n",
    "device = 'cuda'\n",
    "sr_path = 'path/to/sr_diffusion_model.pt'\n",
    "\n",
    "cheff_sr = CheffSRModel(model_path=sr_path, device=device)\n",
    "\n",
    "# Create an \"image\"\n",
    "img = torch.rand((1, 1, 256, 256), device=device)\n",
    "\n",
    "# Predict super resolution image\n",
    "img_sr = cheff_sr.sample(\n",
    "    img=img,\n",
    "    method='ddpm'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apart from directly converting tensors, the SR model also allows to directly upsample paths and directories."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Upscale image from path.\n",
    "img_path = 'path/to/image.png'\n",
    "img_sr = cheff_sr.sample_path(path=img_path, method='ddpm')\n",
    "\n",
    "# Upscale a full directory\n",
    "cheff_sr.sample_directory(\n",
    "    # Take images from here\n",
    "    source_dir='path/to/sourcedir',\n",
    "    # The resulting images will be saved here\n",
    "    target_dir='path/to/targetdir',\n",
    "    # Batch size in SR model\n",
    "    batch_size=4,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Report-to-Chest X-ray Synthesis\n",
    "\n",
    "For the text-conditional synthesis task, we offer an extra module `CheffLDMT2I`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from cheff import CheffLDMT2I\n",
    "\n",
    "device = 'cuda'\n",
    "sdm_path = 'path/to/semantic_diffusion_model_w_text.pt'\n",
    "ae_path = 'path/to/autoencoder_model.pt'\n",
    "\n",
    "cheff_t2i = CheffLDMT2I(model_path=sdm_path, ae_path=ae_path, device=device)\n",
    "\n",
    "prompt = 'Large right-sided pleural effusion.'\n",
    "\n",
    "img = cheff_t2i.sample(\n",
    "    conditioning=prompt,\n",
    "    sampling_steps=100,\n",
    "    eta=1.0,\n",
    "    decode=True\n",
    ")\n",
    "\n",
    "img.clamp_(-1, 1)\n",
    "img = (img + 1) / 2\n",
    "to_pil_image(img[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
